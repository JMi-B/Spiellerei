#elt
Was ist ELT?
- Extract
	Daten herauslÃ¶sen.
	- Durch Verbindung mit einer Datenquelle wie einer API oder als Rohdaten wie z. B. ein Text. 
	- Dabei ist wichtig was fÃ¼r Daten vorhanden sind, in welchem Format sie vorliegen, brauche ich sie alle oder nur einen Teil
- Transform
	Daten Aufbereiten
	- Was will ich wissen
	- Wie muss ich die Daten verÃ¤ndern, bereinigen, zusammenfassen, aufteilen oder Berechnen um die Gesuchte Aussage treffen zu kÃ¶nnen
- Load
	Daten einlesenen
		- Die Daten in ein Zeilsystem Ã¼bertragen



Ãœbernahme aus dem Script [[C:\Users\juliane.bonenkamp\Documents\data-prozess-20250714\Daten und Prozessanalyse\Woche 1\Tag 5\05 - Grundlagen von ETL.md| ELT]]

# ğŸ§± Grundlagen von ETL (Extract â€“ Transform â€“ Load)

ETL steht fÃ¼r **Extract (Extrahieren)**, **Transform (Transformieren)** und **Load (Laden)**. Es handelt sich um einen zentralen Prozess der Datenintegration und Datenverarbeitung â€“ insbesondere in **Data Warehouses**, **Business Intelligence**, **Datenanalyse** und **Data Pipelines**.

---

## ğŸ” 1. Extract (Daten extrahieren)

### Ziel:
Daten aus einer oder mehreren **heterogenen Quellen** gewinnen.

### Typische Datenquellen:
- Relationale Datenbanken (z.â€¯B. MySQL, PostgreSQL)
- NoSQL-Datenbanken (z.â€¯B. MongoDB)
- Dateien (CSV, JSON, XML, Excel, etc.)
- APIs und Webservices (REST, SOAP)
- Logs, Sensor- oder Telemetriedaten

### Extraktionstypen:
- **Full Extraction**: Gesamtdatenbestand wird regelmÃ¤ÃŸig gezogen
- **Incremental Extraction**: Nur neue oder verÃ¤nderte Daten werden extrahiert

---

## ğŸ”§ 2. Transform (Daten transformieren)

### Ziel:
Die Daten so umwandeln, dass sie fÃ¼r das Zielsystem geeignet und konsistent sind.

### Typische Transformationen:
- **Datenbereinigung**: Fehlerhafte, unvollstÃ¤ndige oder doppelte Daten korrigieren
- **Datenanreicherung**: HinzufÃ¼gen externer Informationen (z.â€¯B. aus Referenztabellen)
- **Formatkonvertierung**: z.â€¯B. Zeitstempel vereinheitlichen
- **Aggregation**: Summen, Durchschnitte, Gruppierungen
- **Validierung**: PrÃ¼fen auf GeschÃ¤ftsregeln, z.â€¯B. Pflichtfelder
- **Spalten/Zeilen filtern, umbenennen, neu strukturieren**

### Tools und Konzepte:
- SQL-Transformationen
- Python / Pandas, petl, PySpark
- Mapping-Tabellen
- GeschÃ¤ftsregeln (Business Rules)

---

## ğŸ—ƒï¸ 3. Load (Daten laden)

### Ziel:
Die transformierten Daten in ein **Zielsystem** integrieren.

### Zielsysteme:
- Data Warehouse (z.â€¯B. Snowflake, BigQuery, Redshift)
- Datenbanken (z.â€¯B. MariaDB, PostgreSQL)
- Data Lakes
- Dashboards / Analyse-Tools

### Ladevarianten:
- **Initial Load**: ErstbefÃ¼llung
- **Incremental Load**: Nur neue/geÃ¤nderte Daten
- **Batch Load**: Zeitgesteuerte LadevorgÃ¤nge
- **Streaming Load**: Laufende Datenverarbeitung in Echtzeit

---

## ğŸ§° Werkzeuge (Beispiele):

| Tool           | Typ            | Bemerkung                                   |
| -------------- | -------------- | ------------------------------------------- |
| Apache NiFi    | GUI-basiert    | Visuelle Flows, gut fÃ¼r einfache Pipelines  |
| Talend         | GUI-basiert    | Komplexe Workflows, Business-nah            |
| petl           | Python         | Leichtgewichtig fÃ¼r einfache ETL-Skripte    |
| Pandas         | Python         | Datenanalyse, auch fÃ¼r ETL nutzbar          |
| Apache Airflow | Orchestrierung | Zeitplanung und Abfolge komplexer Pipelines |
| PySpark        | Big Data       | FÃ¼r groÃŸe verteilte Datenmengen             |

---

## âš™ï¸ Typische AnwendungsfÃ¤lle:

- ZusammenfÃ¼hrung von Kundendaten aus CRM, Webshop und Support-System
- Erstellung von Reports (z.â€¯B. Umsatz nach Region)
- Datenmigration in ein neues System
- Konsolidierung von Logfiles aus verschiedenen Servern

---

## ğŸ“Œ Wichtige Herausforderungen:

- **DatenqualitÃ¤t**: Ungenaue oder inkonsistente Daten erschweren Analysen
- **Latenz**: Bei groÃŸen Datenmengen sind Effizienz und Performance entscheidend
- **Fehlertoleranz**: Wiederaufnahme bei Fehlern (Retry, Logging)
- **Versionierung und Historisierung**: Zeitliche GÃ¼ltigkeit von Daten
- **Datenschutz**: DSGVO-konforme Verarbeitung
